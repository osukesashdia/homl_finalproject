{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dce854f",
   "metadata": {},
   "source": [
    "# German Credit Data - AI Model Implementation\n",
    "\n",
    "This notebook implements a machine learning model to predict credit risk using the German Credit dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076cbf5",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5832b",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90472247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the German Credit dataset\n",
    "data_path = '/Users/RS/Downloads/statlog+german+credit+data/german.data-numeric'\n",
    "column_names = [f'feature_{i}' for i in range(1, 25)] + ['target']\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(data_path, sep='\\s+', header=None, names=column_names)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9c0ff",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9373450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# Convert target from 1,2 to 0,1 (1=good credit -> 0, 2=bad credit -> 1)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target'].map({1: 0, 2: 1})\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution after mapping:\")\n",
    "print(f\"Good credit (0): {sum(y == 0)}\")\n",
    "print(f\"Bad credit (1): {sum(y == 1)}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nData preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b924afc",
   "metadata": {},
   "source": [
    "## 4. Train Multiple AI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8267d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Support Vector Machine': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'roc_auc': roc_auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2a627",
   "metadata": {},
   "source": [
    "## 5. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[name]['accuracy'] for name in results.keys()],\n",
    "    'ROC-AUC': [results[name]['roc_auc'] for name in results.keys()]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Accuracy', ascending=False)\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].barh(comparison_df['Model'], comparison_df['Accuracy'], color='skyblue')\n",
    "axes[0].set_xlabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlim(0, 1)\n",
    "for i, v in enumerate(comparison_df['Accuracy']):\n",
    "    axes[0].text(v + 0.01, i, f'{v:.4f}', va='center')\n",
    "\n",
    "# ROC-AUC comparison\n",
    "axes[1].barh(comparison_df['Model'], comparison_df['ROC-AUC'], color='lightcoral')\n",
    "axes[1].set_xlabel('ROC-AUC Score', fontsize=12)\n",
    "axes[1].set_title('Model ROC-AUC Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlim(0, 1)\n",
    "for i, v in enumerate(comparison_df['ROC-AUC']):\n",
    "    axes[1].text(v + 0.01, i, f'{v:.4f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"\\nBest Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367cef0",
   "metadata": {},
   "source": [
    "## 6. Detailed Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from best model\n",
    "best_y_pred = results[best_model_name]['y_pred']\n",
    "best_y_pred_proba = results[best_model_name]['y_pred_proba']\n",
    "\n",
    "# Classification Report\n",
    "print(f\"Classification Report for {best_model_name}:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, best_y_pred, target_names=['Good Credit', 'Bad Credit']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_y_pred)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0], \n",
    "            xticklabels=['Good Credit', 'Bad Credit'],\n",
    "            yticklabels=['Good Credit', 'Bad Credit'])\n",
    "axes[0].set_title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, best_y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, best_y_pred_proba)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title(f'ROC Curve - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3278869",
   "metadata": {},
   "source": [
    "## 7. Make Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b437781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict credit risk for new customers\n",
    "def predict_credit_risk(new_data, model=best_model, scaler=scaler):\n",
    "    \"\"\"\n",
    "    Predict credit risk for new customer data\n",
    "    \n",
    "    Parameters:\n",
    "    new_data: DataFrame with 24 features (same as training data)\n",
    "    model: Trained model to use for prediction\n",
    "    scaler: Fitted scaler for feature scaling\n",
    "    \n",
    "    Returns:\n",
    "    predictions: Array of predictions (0=Good Credit, 1=Bad Credit)\n",
    "    probabilities: Array of probability scores for bad credit\n",
    "    \"\"\"\n",
    "    # Scale the features\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(new_data_scaled)\n",
    "    probabilities = model.predict_proba(new_data_scaled)[:, 1]\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "# Example: Make predictions on first 5 test samples\n",
    "sample_data = X_test.iloc[:5]\n",
    "predictions, probabilities = predict_credit_risk(sample_data)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    'Sample': range(1, 6),\n",
    "    'Prediction': ['Bad Credit' if p == 1 else 'Good Credit' for p in predictions],\n",
    "    'Risk Probability': [f'{prob:.2%}' for prob in probabilities],\n",
    "    'Actual': ['Bad Credit' if y == 1 else 'Good Credit' for y in y_test.iloc[:5]]\n",
    "})\n",
    "\n",
    "print(\"Prediction Results on Sample Data:\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nâœ“ Predictions completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e1547",
   "metadata": {},
   "source": [
    "## 8. Feature Importance (for tree-based models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd560871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if best model has feature importance\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(\"=\"*50)\n",
    "    print(feature_importance.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize top 15 features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'], color='steelblue')\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.title(f'Top 15 Feature Importance - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"{best_model_name} does not provide feature importance scores.\")\n",
    "    print(\"Feature importance is available for Random Forest and Gradient Boosting models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87b78b",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook implemented a complete machine learning pipeline for credit risk prediction:\n",
    "\n",
    "1. **Data Loading**: Loaded German Credit dataset with 1000 samples and 24 features\n",
    "2. **Preprocessing**: Split data (80/20), standardized features\n",
    "3. **Model Training**: Trained 4 different models (Logistic Regression, Random Forest, Gradient Boosting, SVM)\n",
    "4. **Evaluation**: Compared models using accuracy and ROC-AUC metrics\n",
    "5. **Predictions**: Created a function to predict credit risk for new customers\n",
    "\n",
    "**Key Results**:\n",
    "- Best performing model automatically selected\n",
    "- Detailed performance metrics and visualizations\n",
    "- Ready-to-use prediction function for new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9048d",
   "metadata": {},
   "source": [
    "## 10. Explainable AI - Understanding Model Decisions\n",
    "\n",
    "Using SHAP (SHapley Additive exPlanations) and LIME to explain predictions and provide actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c340f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for explainable AI\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['shap', 'lime']\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ“ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"âœ“ {package} installed successfully\")\n",
    "\n",
    "print(\"\\nAll explainability packages ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044aa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from lime import lime_tabular\n",
    "\n",
    "# Initialize SHAP explainer for the best model\n",
    "print(f\"Creating SHAP explainer for {best_model_name}...\")\n",
    "\n",
    "# Use appropriate explainer based on model type\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "else:\n",
    "    # For other models, use KernelExplainer with a sample of training data\n",
    "    explainer = shap.KernelExplainer(best_model.predict_proba, shap.sample(X_train_scaled, 100))\n",
    "\n",
    "# Calculate SHAP values for test set (using a sample for efficiency)\n",
    "print(\"Calculating SHAP values (this may take a moment)...\")\n",
    "shap_sample_size = min(100, len(X_test_scaled))\n",
    "shap_values = explainer.shap_values(X_test_scaled[:shap_sample_size])\n",
    "\n",
    "# For binary classification, get SHAP values for the positive class (bad credit)\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_bad_credit = shap_values[1]\n",
    "else:\n",
    "    shap_values_bad_credit = shap_values\n",
    "\n",
    "print(\"âœ“ SHAP analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b7722",
   "metadata": {},
   "source": [
    "### 10.1 Global Feature Importance - What Matters Most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot - shows which features are most important\n",
    "print(\"Global Feature Importance Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values_bad_credit, X_test.iloc[:shap_sample_size], \n",
    "                  plot_type=\"bar\", show=False)\n",
    "plt.title('Feature Importance for Credit Risk Prediction', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean absolute SHAP values\n",
    "mean_shap = np.abs(shap_values_bad_credit).mean(axis=0)\n",
    "feature_importance_shap = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': mean_shap\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (SHAP Analysis):\")\n",
    "print(feature_importance_shap.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9738f25",
   "metadata": {},
   "source": [
    "### 10.2 SHAP Summary Plot - Feature Impact Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Beeswarm plot - shows how feature values affect predictions\n",
    "print(\"Feature Impact Analysis\")\n",
    "print(\"=\"*70)\n",
    "print(\"Red dots = Higher feature values\")\n",
    "print(\"Blue dots = Lower feature values\")\n",
    "print(\"X-axis = Impact on predicting bad credit (positive = increases bad credit risk)\\n\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "shap.summary_plot(shap_values_bad_credit, X_test.iloc[:shap_sample_size], show=False)\n",
    "plt.title('How Feature Values Impact Credit Risk Prediction', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Insights:\")\n",
    "print(\"   - Features pushing RIGHT increase bad credit risk\")\n",
    "print(\"   - Features pushing LEFT decrease bad credit risk (improve credit)\")\n",
    "print(\"   - Color shows if high (red) or low (blue) values drive the effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef7cee",
   "metadata": {},
   "source": [
    "### 10.3 Individual Prediction Explanation - Why Was This Person Denied?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1157105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a person who was predicted to have bad credit\n",
    "bad_credit_indices = np.where(y_test.iloc[:shap_sample_size].values == 1)[0]\n",
    "\n",
    "if len(bad_credit_indices) > 0:\n",
    "    # Pick the first person with bad credit\n",
    "    person_idx = bad_credit_indices[0]\n",
    "    \n",
    "    print(f\"Explaining prediction for Person #{person_idx + 1}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Actual Credit Status: Bad Credit\")\n",
    "    print(f\"Model Prediction: {'Bad Credit' if results[best_model_name]['y_pred'][person_idx] == 1 else 'Good Credit'}\")\n",
    "    print(f\"Risk Probability: {results[best_model_name]['y_pred_proba'][person_idx]:.2%}\\n\")\n",
    "    \n",
    "    # SHAP Waterfall plot - shows how each feature contributed to this prediction\n",
    "    shap.plots.waterfall(shap.Explanation(\n",
    "        values=shap_values_bad_credit[person_idx],\n",
    "        base_values=explainer.expected_value[1] if isinstance(explainer.expected_value, np.ndarray) else explainer.expected_value,\n",
    "        data=X_test.iloc[person_idx].values,\n",
    "        feature_names=X.columns.tolist()\n",
    "    ), show=False)\n",
    "    plt.title(f'Why Person #{person_idx + 1} Was Predicted as Bad Credit Risk', \n",
    "              fontsize=12, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ’¡ How to read this chart:\")\n",
    "    print(\"   - Start from the base value (average prediction)\")\n",
    "    print(\"   - Red bars push prediction toward BAD credit (higher risk)\")\n",
    "    print(\"   - Blue bars push prediction toward GOOD credit (lower risk)\")\n",
    "    print(\"   - The final value is the model's prediction for this person\")\n",
    "else:\n",
    "    print(\"No bad credit examples found in the sample. Using first person instead.\")\n",
    "    person_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3481d",
   "metadata": {},
   "source": [
    "### 10.4 LIME Explanation - Alternative Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LIME explainer\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer(\n",
    "    X_train_scaled,\n",
    "    feature_names=X.columns.tolist(),\n",
    "    class_names=['Good Credit', 'Bad Credit'],\n",
    "    mode='classification',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Explain the same person using LIME\n",
    "print(f\"LIME Explanation for Person #{person_idx + 1}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "lime_exp = lime_explainer.explain_instance(\n",
    "    X_test_scaled[person_idx],\n",
    "    best_model.predict_proba,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "# Show LIME explanation\n",
    "fig = lime_exp.as_pyplot_figure()\n",
    "plt.title(f'LIME Explanation for Person #{person_idx + 1}', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ LIME shows the top features that influenced this specific prediction\")\n",
    "print(\"   - Orange bars = Features pushing toward BAD credit\")\n",
    "print(\"   - Blue bars = Features pushing toward GOOD credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005721d",
   "metadata": {},
   "source": [
    "### 10.5 Actionable Insights - What Should People Do to Get Good Credit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d157cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actionable_recommendations(person_features, shap_values_person, feature_names):\n",
    "    \"\"\"\n",
    "    Generate actionable recommendations based on SHAP values\n",
    "    \"\"\"\n",
    "    # Get feature contributions\n",
    "    contributions = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Value': person_features,\n",
    "        'SHAP_Value': shap_values_person,\n",
    "        'Impact': ['Increases Risk' if s > 0 else 'Decreases Risk' for s in shap_values_person]\n",
    "    })\n",
    "    \n",
    "    # Sort by absolute SHAP value\n",
    "    contributions['Abs_SHAP'] = np.abs(contributions['SHAP_Value'])\n",
    "    contributions = contributions.sort_values('Abs_SHAP', ascending=False)\n",
    "    \n",
    "    return contributions\n",
    "\n",
    "# Generate recommendations for the person we analyzed\n",
    "person_features = X_test.iloc[person_idx].values\n",
    "recommendations = generate_actionable_recommendations(\n",
    "    person_features,\n",
    "    shap_values_bad_credit[person_idx],\n",
    "    X.columns.tolist()\n",
    ")\n",
    "\n",
    "print(\"ACTIONABLE RECOMMENDATIONS TO IMPROVE CREDIT SCORE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAnalysis for Person #{person_idx + 1}\")\n",
    "print(f\"Current Risk Probability: {results[best_model_name]['y_pred_proba'][person_idx]:.2%}\\n\")\n",
    "\n",
    "# Show top factors hurting credit (positive SHAP values)\n",
    "print(\"ðŸ”´ TOP FACTORS HURTING YOUR CREDIT (Need Improvement):\")\n",
    "print(\"-\" * 70)\n",
    "negative_factors = recommendations[recommendations['SHAP_Value'] > 0].head(5)\n",
    "for idx, row in negative_factors.iterrows():\n",
    "    print(f\"   â€¢ {row['Feature']}: Current value = {row['Value']:.2f}\")\n",
    "    print(f\"     Impact: +{row['SHAP_Value']:.4f} (increases bad credit risk)\")\n",
    "    print()\n",
    "\n",
    "# Show top factors helping credit (negative SHAP values)\n",
    "print(\"\\nðŸŸ¢ TOP FACTORS HELPING YOUR CREDIT (Keep it up!):\")\n",
    "print(\"-\" * 70)\n",
    "positive_factors = recommendations[recommendations['SHAP_Value'] < 0].head(5)\n",
    "for idx, row in positive_factors.iterrows():\n",
    "    print(f\"   â€¢ {row['Feature']}: Current value = {row['Value']:.2f}\")\n",
    "    print(f\"     Impact: {row['SHAP_Value']:.4f} (decreases bad credit risk)\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š DETAILED FEATURE CONTRIBUTIONS:\")\n",
    "print(recommendations[['Feature', 'Value', 'SHAP_Value', 'Impact']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed407be8",
   "metadata": {},
   "source": [
    "### 10.6 What-If Analysis - Simulate Changes to Improve Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52500337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_credit_improvement(person_data, model, scaler, feature_names, modifications):\n",
    "    \"\"\"\n",
    "    Simulate what happens when someone improves certain features\n",
    "    \n",
    "    modifications: dict of {feature_name: new_value}\n",
    "    \"\"\"\n",
    "    # Create a copy of the person's data\n",
    "    modified_data = person_data.copy()\n",
    "    \n",
    "    # Apply modifications\n",
    "    for feature, new_value in modifications.items():\n",
    "        if feature in feature_names:\n",
    "            feature_idx = feature_names.index(feature)\n",
    "            modified_data[feature_idx] = new_value\n",
    "    \n",
    "    # Scale and predict\n",
    "    modified_data_scaled = scaler.transform([modified_data])\n",
    "    new_prediction = model.predict(modified_data_scaled)[0]\n",
    "    new_probability = model.predict_proba(modified_data_scaled)[0][1]\n",
    "    \n",
    "    return new_prediction, new_probability\n",
    "\n",
    "# Get the person's original data\n",
    "original_person = X_test.iloc[person_idx].values\n",
    "original_prob = results[best_model_name]['y_pred_proba'][person_idx]\n",
    "\n",
    "print(\"WHAT-IF ANALYSIS: Simulating Improvements\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Original Bad Credit Risk Probability: {original_prob:.2%}\\n\")\n",
    "\n",
    "# Get the most impactful negative features\n",
    "top_negative_features = negative_factors.head(3)\n",
    "\n",
    "print(\"Let's simulate improvements to the top 3 negative factors:\\n\")\n",
    "\n",
    "scenarios = []\n",
    "\n",
    "# Scenario 1: Improve the worst feature\n",
    "if len(top_negative_features) > 0:\n",
    "    worst_feature = top_negative_features.iloc[0]['Feature']\n",
    "    current_value = top_negative_features.iloc[0]['Value']\n",
    "    \n",
    "    # Simulate reducing the feature value by 20%\n",
    "    new_value = current_value * 0.8\n",
    "    modifications = {worst_feature: new_value}\n",
    "    \n",
    "    new_pred, new_prob = simulate_credit_improvement(\n",
    "        original_person, best_model, scaler, X.columns.tolist(), modifications\n",
    "    )\n",
    "    \n",
    "    print(f\"Scenario 1: Improve {worst_feature}\")\n",
    "    print(f\"   Change: {current_value:.2f} â†’ {new_value:.2f} (20% reduction)\")\n",
    "    print(f\"   New Risk Probability: {new_prob:.2%}\")\n",
    "    print(f\"   Risk Change: {(new_prob - original_prob):.2%}\")\n",
    "    print(f\"   Result: {'âœ“ APPROVED for Good Credit!' if new_pred == 0 else 'âœ— Still Bad Credit Risk'}\\n\")\n",
    "    \n",
    "    scenarios.append({\n",
    "        'Scenario': 'Improve worst feature',\n",
    "        'Original': f'{original_prob:.2%}',\n",
    "        'New': f'{new_prob:.2%}',\n",
    "        'Change': f'{(new_prob - original_prob):.2%}',\n",
    "        'Status': 'Approved' if new_pred == 0 else 'Denied'\n",
    "    })\n",
    "\n",
    "# Scenario 2: Improve top 2 features\n",
    "if len(top_negative_features) >= 2:\n",
    "    modifications = {}\n",
    "    print(f\"Scenario 2: Improve top 2 negative factors\")\n",
    "    for idx in range(2):\n",
    "        feature = top_negative_features.iloc[idx]['Feature']\n",
    "        current_value = top_negative_features.iloc[idx]['Value']\n",
    "        new_value = current_value * 0.8\n",
    "        modifications[feature] = new_value\n",
    "        print(f\"   {feature}: {current_value:.2f} â†’ {new_value:.2f}\")\n",
    "    \n",
    "    new_pred, new_prob = simulate_credit_improvement(\n",
    "        original_person, best_model, scaler, X.columns.tolist(), modifications\n",
    "    )\n",
    "    \n",
    "    print(f\"   New Risk Probability: {new_prob:.2%}\")\n",
    "    print(f\"   Risk Change: {(new_prob - original_prob):.2%}\")\n",
    "    print(f\"   Result: {'âœ“ APPROVED for Good Credit!' if new_pred == 0 else 'âœ— Still Bad Credit Risk'}\\n\")\n",
    "    \n",
    "    scenarios.append({\n",
    "        'Scenario': 'Improve top 2 features',\n",
    "        'Original': f'{original_prob:.2%}',\n",
    "        'New': f'{new_prob:.2%}',\n",
    "        'Change': f'{(new_prob - original_prob):.2%}',\n",
    "        'Status': 'Approved' if new_pred == 0 else 'Denied'\n",
    "    })\n",
    "\n",
    "# Scenario 3: Improve all top 3 features\n",
    "if len(top_negative_features) >= 3:\n",
    "    modifications = {}\n",
    "    print(f\"Scenario 3: Improve all top 3 negative factors\")\n",
    "    for idx in range(3):\n",
    "        feature = top_negative_features.iloc[idx]['Feature']\n",
    "        current_value = top_negative_features.iloc[idx]['Value']\n",
    "        new_value = current_value * 0.8\n",
    "        modifications[feature] = new_value\n",
    "        print(f\"   {feature}: {current_value:.2f} â†’ {new_value:.2f}\")\n",
    "    \n",
    "    new_pred, new_prob = simulate_credit_improvement(\n",
    "        original_person, best_model, scaler, X.columns.tolist(), modifications\n",
    "    )\n",
    "    \n",
    "    print(f\"   New Risk Probability: {new_prob:.2%}\")\n",
    "    print(f\"   Risk Change: {(new_prob - original_prob):.2%}\")\n",
    "    print(f\"   Result: {'âœ“ APPROVED for Good Credit!' if new_pred == 0 else 'âœ— Still Bad Credit Risk'}\\n\")\n",
    "    \n",
    "    scenarios.append({\n",
    "        'Scenario': 'Improve top 3 features',\n",
    "        'Original': f'{original_prob:.2%}',\n",
    "        'New': f'{new_prob:.2%}',\n",
    "        'Change': f'{(new_prob - original_prob):.2%}',\n",
    "        'Status': 'Approved' if new_pred == 0 else 'Denied'\n",
    "    })\n",
    "\n",
    "# Display summary\n",
    "if scenarios:\n",
    "    print(\"=\"*70)\n",
    "    print(\"SUMMARY OF WHAT-IF SCENARIOS:\")\n",
    "    scenario_df = pd.DataFrame(scenarios)\n",
    "    print(scenario_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00df85e",
   "metadata": {},
   "source": [
    "### 10.7 Interactive Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcfeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_any_person(person_index, X_test, y_test, model, scaler, explainer, feature_names):\n",
    "    \"\"\"\n",
    "    Complete explainability analysis for any person in the test set\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(f\"CREDIT ANALYSIS REPORT FOR PERSON #{person_index + 1}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get person's data\n",
    "    person_features = X_test.iloc[person_index].values\n",
    "    person_features_scaled = scaler.transform([person_features])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(person_features_scaled)[0]\n",
    "    probability = model.predict_proba(person_features_scaled)[0][1]\n",
    "    actual = y_test.iloc[person_index]\n",
    "    \n",
    "    # Display prediction\n",
    "    print(f\"\\nðŸ“Š PREDICTION RESULTS:\")\n",
    "    print(f\"   Actual Status: {'Bad Credit' if actual == 1 else 'Good Credit'}\")\n",
    "    print(f\"   Predicted Status: {'Bad Credit' if prediction == 1 else 'Good Credit'}\")\n",
    "    print(f\"   Bad Credit Risk Probability: {probability:.2%}\")\n",
    "    print(f\"   Model Accuracy: {'âœ“ Correct' if prediction == actual else 'âœ— Incorrect'}\")\n",
    "    \n",
    "    # Calculate SHAP values for this person\n",
    "    shap_values_person = explainer.shap_values(person_features_scaled)\n",
    "    if isinstance(shap_values_person, list):\n",
    "        shap_values_person = shap_values_person[1][0]\n",
    "    else:\n",
    "        shap_values_person = shap_values_person[0]\n",
    "    \n",
    "    # Generate recommendations\n",
    "    contributions = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Value': person_features,\n",
    "        'SHAP_Value': shap_values_person,\n",
    "        'Impact': ['Increases Risk' if s > 0 else 'Decreases Risk' for s in shap_values_person]\n",
    "    })\n",
    "    contributions['Abs_SHAP'] = np.abs(contributions['SHAP_Value'])\n",
    "    contributions = contributions.sort_values('Abs_SHAP', ascending=False)\n",
    "    \n",
    "    # Show top negative and positive factors\n",
    "    print(f\"\\nðŸ”´ TOP 3 FACTORS HURTING CREDIT:\")\n",
    "    negative = contributions[contributions['SHAP_Value'] > 0].head(3)\n",
    "    for idx, row in negative.iterrows():\n",
    "        print(f\"   â€¢ {row['Feature']}: {row['Value']:.2f} (Impact: +{row['SHAP_Value']:.4f})\")\n",
    "    \n",
    "    print(f\"\\nðŸŸ¢ TOP 3 FACTORS HELPING CREDIT:\")\n",
    "    positive = contributions[contributions['SHAP_Value'] < 0].head(3)\n",
    "    for idx, row in positive.iterrows():\n",
    "        print(f\"   â€¢ {row['Feature']}: {row['Value']:.2f} (Impact: {row['SHAP_Value']:.4f})\")\n",
    "    \n",
    "    # Action recommendations\n",
    "    print(f\"\\nðŸ’¡ RECOMMENDED ACTIONS TO IMPROVE CREDIT:\")\n",
    "    if prediction == 1 or probability > 0.5:\n",
    "        print(\"   Focus on improving these features to reduce credit risk:\")\n",
    "        for idx, row in negative.head(3).iterrows():\n",
    "            print(f\"   âœ“ Work on {row['Feature']} (current: {row['Value']:.2f})\")\n",
    "    else:\n",
    "        print(\"   âœ“ Your credit profile is good! Keep maintaining:\")\n",
    "        for idx, row in positive.head(3).iterrows():\n",
    "            print(f\"   â€¢ {row['Feature']} at {row['Value']:.2f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return contributions\n",
    "\n",
    "# Example: Analyze any person from the test set\n",
    "print(\"You can now analyze any person from the test set!\\n\")\n",
    "print(f\"Available indices: 0 to {len(X_test) - 1}\")\n",
    "print(\"\\nExample analysis for Person #5:\\n\")\n",
    "\n",
    "if len(X_test) >= 5:\n",
    "    analysis = explain_any_person(4, X_test, y_test, best_model, scaler, explainer, X.columns.tolist())\n",
    "else:\n",
    "    print(\"Not enough test samples available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1bbc19",
   "metadata": {},
   "source": [
    "### 10.8 Visualize Decision Boundary and Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Dependence plots - show how individual features affect predictions\n",
    "print(\"Feature Relationship Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get top 3 most important features\n",
    "top_3_features = feature_importance_shap.head(3)['Feature'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, feature in enumerate(top_3_features):\n",
    "    feature_idx = X.columns.tolist().index(feature)\n",
    "    shap.dependence_plot(\n",
    "        feature_idx,\n",
    "        shap_values_bad_credit,\n",
    "        X_test.iloc[:shap_sample_size],\n",
    "        ax=axes[idx],\n",
    "        show=False\n",
    "    )\n",
    "    axes[idx].set_title(f'Impact of {feature}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ How to read these plots:\")\n",
    "print(\"   - X-axis: Feature value\")\n",
    "print(\"   - Y-axis: SHAP value (impact on prediction)\")\n",
    "print(\"   - Higher SHAP value = Higher bad credit risk\")\n",
    "print(\"   - Color: Interaction effect with another feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f615c3",
   "metadata": {},
   "source": [
    "### 10.9 Summary - Key Takeaways for Credit Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56035062",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"KEY INSIGHTS FROM EXPLAINABLE AI ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š GLOBAL INSIGHTS - What Matters Most for Credit Decisions:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nTop 5 Most Important Features Overall:\")\n",
    "for idx, row in feature_importance_shap.head(5).iterrows():\n",
    "    print(f\"   {idx + 1}. {row['Feature']} (Importance: {row['Importance']:.4f})\")\n",
    "\n",
    "print(\"\\n\\nðŸŽ¯ ACTIONABLE RECOMMENDATIONS FOR CUSTOMERS:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "To improve your chances of getting good credit:\n",
    "\n",
    "1. FOCUS ON HIGH-IMPACT FACTORS\n",
    "   â€¢ Identify your top 3-5 negative features using the analysis above\n",
    "   â€¢ These have the biggest impact on your credit decision\n",
    "\n",
    "2. UNDERSTAND YOUR SITUATION\n",
    "   â€¢ Use the SHAP waterfall plot to see YOUR specific factors\n",
    "   â€¢ Each person's situation is unique\n",
    "\n",
    "3. SIMULATE IMPROVEMENTS\n",
    "   â€¢ Use the what-if analysis to see how changes affect your score\n",
    "   â€¢ Focus on realistic, achievable improvements\n",
    "\n",
    "4. MONITOR PROGRESS\n",
    "   â€¢ Track changes in the most important features\n",
    "   â€¢ Small improvements in high-impact areas = Big results\n",
    "\n",
    "5. MAINTAIN POSITIVE FACTORS\n",
    "   â€¢ Don't neglect features that are already helping you\n",
    "   â€¢ Keep doing what's working!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nðŸ’¡ HOW TO USE THIS ANALYSIS:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "1. Run the notebook with your data\n",
    "2. Check individual explanations using explain_any_person()\n",
    "3. Use what-if scenarios to plan improvements\n",
    "4. Focus on the most important features first\n",
    "5. Re-evaluate after making changes\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ… EXPLAINABLE AI IMPLEMENTATION COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
